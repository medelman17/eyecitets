---
phase: 08-parallel-linking-quality-validation
plan: 03
type: execute
wave: 2
depends_on: ["08-01", "08-02"]
files_modified:
  - tests/fixtures/golden-corpus.json
  - tests/integration/goldenCorpus.test.ts
  - .github/workflows/ci.yml
autonomous: true

must_haves:
  truths:
    - "Golden test corpus exists with 20-30 real-world legal text samples"
    - "Integration test validates extraction accuracy against golden corpus"
    - "Bundle size remains under 50KB gzipped"
    - "Performance remains under 100ms for 10KB documents"
    - "CI enforces bundle size and performance thresholds"
  artifacts:
    - path: "tests/fixtures/golden-corpus.json"
      provides: "Structured test data with real-world legal text samples"
      min_lines: 400
    - path: "tests/integration/goldenCorpus.test.ts"
      provides: "Golden corpus test runner"
      exports: ["describe"]
      min_lines: 80
    - path: ".github/workflows/ci.yml"
      provides: "CI enforcement for size/perf thresholds"
      pattern: "size-limit"
  key_links:
    - from: "tests/integration/goldenCorpus.test.ts"
      to: "tests/fixtures/golden-corpus.json"
      via: "JSON file import"
      pattern: "import.*golden-corpus"
    - from: "tests/integration/goldenCorpus.test.ts"
      to: "extractCitations"
      via: "extraction call for each corpus sample"
      pattern: "extractCitations\\(sample\\.text"
    - from: ".github/workflows/ci.yml"
      to: "pnpm size"
      via: "CI size check enforcement"
      pattern: "pnpm.*size"
---

<objective>
Create golden test corpus for extraction accuracy regression testing and enforce quality targets (bundle size, performance).

Purpose: Phase 8 completes v1.1 Extraction Accuracy milestone. A golden corpus prevents accuracy regressions as the codebase evolves — real-world legal text samples serve as ground truth. Size/performance enforcement ensures the library remains production-ready.

Output: Structured JSON corpus with 20-30 samples, integration test suite, CI enforcement for quality gates.
</objective>

<execution_context>
@/Users/medelman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/medelman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/Users/medelman/GitHub/medelman17/eyecitets/.planning/PROJECT.md
@/Users/medelman/GitHub/medelman17/eyecitets/.planning/ROADMAP.md
@/Users/medelman/GitHub/medelman17/eyecitets/.planning/STATE.md
@/Users/medelman/GitHub/medelman17/eyecitets/.planning/phases/08-parallel-linking-quality-validation/08-CONTEXT.md
@/Users/medelman/GitHub/medelman17/eyecitets/.planning/phases/08-parallel-linking-quality-validation/08-RESEARCH.md

# Prior phase outputs
@/Users/medelman/GitHub/medelman17/eyecitets/.planning/phases/08-parallel-linking-quality-validation/08-01-SUMMARY.md
@/Users/medelman/GitHub/medelman17/eyecitets/.planning/phases/08-parallel-linking-quality-validation/08-02-SUMMARY.md

# Relevant files
@/Users/medelman/GitHub/medelman17/eyecitets/.github/workflows/ci.yml
@/Users/medelman/GitHub/medelman17/eyecitets/size-limit.config.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create golden test corpus with real-world legal text samples</name>
  <files>
    tests/fixtures/golden-corpus.json
  </files>
  <action>
Create `tests/fixtures/golden-corpus.json` with 20-30 samples covering major citation types and v1.1 features.

Per 08-CONTEXT.md: "Claude's discretion on match granularity (key fields vs full snapshot)" — use key field matching (volume, reporter, page, type, caseName, plaintiff, defendant, groupId, parallelCitations) rather than full snapshot. This avoids brittleness from confidence score changes or metadata tweaks.

**Corpus structure:**
```json
{
  "samples": [
    {
      "id": "supreme-court-parallel",
      "description": "Supreme Court parallel citation (3 reporters)",
      "text": "In Roe v. Wade, 410 U.S. 113, 93 S. Ct. 705, 35 L. Ed. 2d 147 (1973), the Court held...",
      "expected": [
        {
          "type": "case",
          "volume": 410,
          "reporter": "U.S.",
          "page": 113,
          "caseName": "Roe v. Wade",
          "plaintiff": "Roe",
          "defendant": "Wade",
          "groupId": "410-U.S.-113",
          "parallelCitations": [
            { "volume": 93, "reporter": "S. Ct.", "page": 705 },
            { "volume": 35, "reporter": "L. Ed. 2d", "page": 147 }
          ]
        },
        {
          "type": "case",
          "volume": 93,
          "reporter": "S. Ct.",
          "page": 705,
          "groupId": "410-U.S.-113"
        },
        {
          "type": "case",
          "volume": 35,
          "reporter": "L. Ed. 2d",
          "page": 147,
          "groupId": "410-U.S.-113"
        }
      ]
    },
    // ... 19-29 more samples
  ]
}
```

**Sample coverage (20-30 total):**

1. **Parallel citations** (5 samples):
   - Supreme Court 3-reporter parallel (U.S. + S. Ct. + L. Ed.)
   - Federal circuit 2-reporter parallel (F.2d + F. Supp.)
   - State parallel citation (Cal. + P.2d)
   - Short 2-reporter parallel
   - 4-reporter parallel (rare but valid)

2. **Case names & party extraction** (5 samples):
   - Standard adversarial (Smith v. Jones)
   - Government plaintiff (United States v. Defendant)
   - Government defendant (Plaintiff v. United States)
   - Procedural prefix (In re Smith, Ex parte Smith, Matter of Smith)
   - Corporate suffixes (Smith Corp. v. Jones, Inc.)

3. **Complex parentheticals** (4 samples):
   - Court + year (9th Cir. 1974)
   - Court + full date (S.D.N.Y. May 15, 1990)
   - Year only (1973)
   - Court only (D.C. Cir.)

4. **Blank pages** (2 samples):
   - Underscore placeholder (500 F.2d ___)
   - Dash placeholder (500 F.2d ---)

5. **Other citation types** (4 samples):
   - U.S. Code (42 U.S.C. § 1983)
   - State code (Cal. Civ. Code § 1542)
   - Neutral citation (2020 WL 123456)
   - Law journal (100 Yale L.J. 500)

6. **Short forms** (4 samples):
   - Id. resolution
   - Supra resolution by party name
   - Short-form case resolution (volume + page)
   - Id. with pincite

7. **Edge cases** (2-6 samples):
   - Multiple citations in sentence
   - Chained parentheticals (1973) (en banc)
   - Pincites (500 F.2d 123, 125-26)
   - Signal words (See, Cf., But see)
   - Embedded citations in footnote text
   - Non-citation false positives (excluded)

Per 08-RESEARCH.md: "Golden corpus should be 20-30 samples covering major citation types and edge cases" — targeting 25 samples for comprehensive coverage without excessive maintenance burden.

Run `node -e 'console.log(JSON.parse(require("fs").readFileSync("tests/fixtures/golden-corpus.json")).samples.length)'` to verify sample count.

Commit: `test(08-03): create golden test corpus with 25 real-world samples`
  </action>
  <verify>
```bash
test -f tests/fixtures/golden-corpus.json
node -e 'const data = JSON.parse(require("fs").readFileSync("tests/fixtures/golden-corpus.json")); console.log("Samples:", data.samples.length)'
```
File exists, contains 20-30 samples.
  </verify>
  <done>
golden-corpus.json created with 20-30 structured samples covering all major citation types and v1.1 features.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create golden corpus integration test runner</name>
  <files>
    tests/integration/goldenCorpus.test.ts
  </files>
  <action>
Create integration test that validates extraction accuracy against golden corpus.

```typescript
import { describe, it, expect } from 'vitest'
import { extractCitations } from '@/extract'
import goldenCorpus from '../fixtures/golden-corpus.json'

describe('Golden Corpus Extraction Accuracy', () => {
  for (const sample of goldenCorpus.samples) {
    it(`extracts ${sample.id}: ${sample.description}`, () => {
      const citations = extractCitations(sample.text)

      expect(citations).toHaveLength(sample.expected.length)

      for (let i = 0; i < sample.expected.length; i++) {
        const actual = citations[i]
        const expected = sample.expected[i]

        // Match key fields only (per 08-CONTEXT.md discretion)
        expect(actual.type).toBe(expected.type)

        if (expected.volume !== undefined) {
          expect(actual.volume).toBe(expected.volume)
        }

        if (expected.reporter !== undefined) {
          expect(actual.reporter).toBe(expected.reporter)
        }

        if (expected.page !== undefined) {
          expect(actual.page).toBe(expected.page)
        }

        if (expected.caseName !== undefined) {
          expect(actual.caseName).toBe(expected.caseName)
        }

        if (expected.plaintiff !== undefined) {
          expect(actual.plaintiff).toBe(expected.plaintiff)
        }

        if (expected.defendant !== undefined) {
          expect(actual.defendant).toBe(expected.defendant)
        }

        if (expected.groupId !== undefined) {
          expect(actual.groupId).toBe(expected.groupId)
        }

        if (expected.parallelCitations !== undefined) {
          expect(actual.parallelCitations).toHaveLength(expected.parallelCitations.length)
          for (let j = 0; j < expected.parallelCitations.length; j++) {
            expect(actual.parallelCitations[j]).toEqual(expected.parallelCitations[j])
          }
        }
      }
    })
  }
})

describe('Quality Targets', () => {
  it('processes 10KB document in under 100ms', () => {
    // Generate 10KB text with multiple citations
    const sampleText = goldenCorpus.samples.map(s => s.text).join('\n\n')
    const text10KB = sampleText.repeat(Math.ceil(10240 / sampleText.length))

    const start = performance.now()
    const citations = extractCitations(text10KB)
    const duration = performance.now() - start

    expect(citations.length).toBeGreaterThan(0)
    expect(duration).toBeLessThan(100)  // QUAL-03 requirement
  })
})
```

Run test suite to verify corpus accuracy:
```bash
pnpm exec vitest run tests/integration/goldenCorpus.test.ts
```

If any samples fail, adjust corpus expected values or fix extraction bugs (bugs found = good! That's what the corpus is for).

Commit: `test(08-03): add golden corpus integration test runner`
  </action>
  <verify>
```bash
pnpm exec vitest run tests/integration/goldenCorpus.test.ts
pnpm test
```
Golden corpus tests pass. Performance test passes (<100ms). All tests pass.
  </verify>
  <done>
goldenCorpus.test.ts created, all samples pass extraction accuracy validation, performance target met.
  </done>
</task>

<task type="auto">
  <name>Task 3: Enforce bundle size and performance in CI</name>
  <files>
    .github/workflows/ci.yml
  </files>
  <action>
Update CI workflow to enforce quality targets.

1. **Check current size configuration:**
   ```bash
   cat size-limit.config.js
   cat .github/workflows/ci.yml | grep -A 10 "size"
   ```

2. **If size check exists:** Verify thresholds are correct (core <50KB gzipped per QUAL-02)

3. **If size check missing:** Add size check step to CI workflow after build step:
   ```yaml
   - name: Check bundle size
     run: pnpm size
   ```

4. **Verify size-limit configuration** in `size-limit.config.js`:
   ```javascript
   module.exports = [
     {
       name: 'Core (ESM)',
       path: 'dist/index.mjs',
       limit: '50 KB',  // QUAL-02 requirement
       gzip: true,
     },
     {
       name: 'Data (lazy)',
       path: 'dist/data/index.mjs',
       limit: '100 KB',  // Reporters database
       gzip: true,
     },
   ]
   ```

5. **Add performance check step** (after test step):
   ```yaml
   - name: Validate quality targets
     run: |
       echo "Running golden corpus performance test..."
       pnpm exec vitest run tests/integration/goldenCorpus.test.ts --reporter=verbose
   ```

Per 08-CONTEXT.md: "Claude's discretion on CI enforcement for size/perf thresholds" — enforcing both in CI to catch regressions early. Failing CI on quality gate violations ensures no degradation.

Run CI workflow locally (or push to branch) to verify enforcement.

Commit: `ci(08-03): enforce bundle size and performance quality targets`
  </action>
  <verify>
```bash
cat .github/workflows/ci.yml | grep -A 5 "size"
pnpm size
pnpm exec vitest run tests/integration/goldenCorpus.test.ts
```
CI workflow includes size and performance checks. Size check passes (<50KB). Performance test passes (<100ms).
  </verify>
  <done>
CI enforces bundle size <50KB gzipped and performance <100ms for 10KB docs. Quality targets validated.
  </done>
</task>

</tasks>

<verification>
Run complete test suite and quality checks:
```bash
pnpm test
pnpm typecheck
pnpm lint
pnpm build
pnpm size
pnpm exec vitest run tests/integration/goldenCorpus.test.ts --reporter=verbose
```

All tests MUST pass. Bundle size under 50KB gzipped. Performance under 100ms for 10KB documents.

Verify CI workflow (if possible):
```bash
git add .
git commit -m "test(08-03): quality validation and golden corpus"
git push
# Check GitHub Actions run status
```
</verification>

<success_criteria>
- ✅ Golden corpus JSON exists with 20-30 real-world samples
- ✅ Samples cover all major citation types (parallel, case names, parentheticals, blank pages, other types, short forms, edge cases)
- ✅ Integration test validates extraction accuracy against corpus
- ✅ All golden corpus tests pass
- ✅ Performance test passes (<100ms for 10KB documents)
- ✅ Bundle size check passes (<50KB gzipped core)
- ✅ CI enforces size and performance thresholds
- ✅ All existing tests pass (no regressions)
- ✅ Zero type errors, zero lint errors
</success_criteria>

<output>
After completion, create `.planning/phases/08-parallel-linking-quality-validation/08-03-SUMMARY.md`
</output>
